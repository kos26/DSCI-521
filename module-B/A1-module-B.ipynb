{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment group 1: Textual feature extraction and numerical comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module B _(35 points)_ Key word in context\n",
    "\n",
    "Key word in context (KWiC) is a common format for concordance lines, i.e., contextualized instances of principal words used in a book. More generally, KWiC is essentially the concept behind the utility of 'find in page' on document viewers and web browsers. This module builds up a KWiC utility for finding key word-containing sentences, and 'most relevant' paragraphs, quickly.\n",
    "\n",
    "__B1.__ _(3 points)_ Start by writing a function called `load_book` that reads in a book based on a provided `book_id` string and returns a list of `paragraphs` from the book. When book data is loaded, you should remove the space characters at the beginning and end of the text (e.g., using `strip()`). Then, to split books into paragraphs, use the `re.split()` method to split the input in cases where there are two or more new lines. Note, that books are in the provided `data/books` directory.\n",
    "\n",
    "Note: this module is not focused on text pre-processing beyond a split into paragraphs; you do _not_ need to remove markup or non-substantive content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B1:Function(3/3)\n",
    "\n",
    "import re\n",
    "\n",
    "def load_book(book_id):\n",
    "    \n",
    "    #---Your code start here---\n",
    "    \n",
    "    #---Your code ends here---\n",
    "    \n",
    "    return paragraphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test your function, lets apply it to look at a few paragraphs from book 84."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B1:SanityCheck\n",
    "paragraphs = load_book('84')\n",
    "print(len(paragraphs))\n",
    "print(paragraphs[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__B2.__ _(10 points)_ Next, write a function called `kwic(paragraphs, search_terms)` that accepts a list of string `paragraphs` and a set of `search_term` strings. The function should:\n",
    "\n",
    "1. initialize `data` as a `defaultdict` of lists\n",
    "2. loop over the `paragraphs` and apply `spacy`'s processing to produce a `doc` for each;\n",
    "3. loop over the `doc.sents` resulting from each `paragraph`;\n",
    "4. loop over the words in each `sentence`;\n",
    "5. check: `if` a `word` is `in` the `search_terms` set;\n",
    "6. `if` (5), then `.append()` the reference under `data[word]` as a list: `[[i, j, k], sentence]`, where `i`, `j`, and `k` refer to the paragraph-in-book, sentence-in-paragraph, and word-in-sentence indices, respectively.\n",
    "\n",
    "Your output, `data`, should then be a default dictionary of lists of the format:\n",
    "```\n",
    "data['word'] = [[[i, j, k], [\"These\", \"are\", \"sentences\", \"containing\", \"the\", \"word\", \"'word'\", \".\"]],\n",
    "                ...,]\n",
    "```\n",
    "\n",
    "Note, we have imported spacy and set it up to use the `\"en\"` model. This will require you to install spacy by running `pip install spacy` and downloading the `\"en\"` model by running the command `python -m spacy download en`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B2:Function(10/10)\n",
    "\n",
    "from collections import defaultdict\n",
    "import spacy\n",
    "nlp = spacy.load(\"en\")\n",
    "\n",
    "def kwic(paragraphs, search_terms = {}):\n",
    "    \n",
    "    #---Your code starts here---\n",
    "\n",
    "    #---Your code ends here---\n",
    "    \n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's test your function using the paragraphs from your `load_book` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B2:SanityCheck\n",
    "kwic(paragraphs, {'Ocean', 'seas'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__B3.__ _(2 points)_ Let's test your `kwic` search function's utility using the pre-processed `paragraphs` from book `84` for the key words `Frankenstein` and `monster` in context. Answer the inline questions about these tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B3:SanityCheck\n",
    "results = kwic(paragraphs, {\"Frankenstein\", \"monster\"})\n",
    "\n",
    "print(\"# of sentences 'Frankenstein' appears in: {}\".format(len(results['Frankenstein'])))\n",
    "print(\"# of sentences 'monster' appears in: {}\".format(len(results['monster'])))\n",
    "print()\n",
    "\n",
    "print(\" \".join(results['Frankenstein'][7][1]))\n",
    "print()\n",
    "print(\" \".join(results['monster'][0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B3:Inline(1/2)\n",
    "\n",
    "# Is the kwic function fast or slow? Print \"Fast\" or \"Slow\"\n",
    "print(\"<KWIC SPEED>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B3:Inline(1/2)\n",
    "\n",
    "# How many sentences does the work Frankenstein appear in? Print the integer (0 is just a placeholder).\n",
    "print(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__B4.__ _(10 pts)_ The cost of _indexing_ a given book turns out to be the limiting factor here for kwic. Presently, we have our pre-processing `load_book` function just splitting a document into paragraphs. Rewrite the `load_book` function to do some additional preprocessing. Specifically, this function should be modified to:\n",
    "\n",
    "1. split a `book` into paragraphs and loop over them, but\n",
    "2. process each paragraph with `spacy`;\n",
    "3. store the `document` as a triple-nested list, so that each word _string_ is reachable via three indices: `word = document[i][j][k]`;\n",
    "4. record an `index = defaultdict(list)` containing a list of `[i,j,k]` lists for each word; and\n",
    "5. `return document, index`\n",
    "\n",
    "Pre-computing the `index` will allow us to efficiently look up the locations of each word's instance in `document`, and the triple-list format of our document will allow us fast access to extract the sentence for KWiC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B4:Function(10/10)\n",
    "\n",
    "def load_book(book_id):\n",
    "    \n",
    "    #---Your code starts here---\n",
    "    \n",
    "    #---Your code ends here---\n",
    "                    \n",
    "    return(document, index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's test your new function on `book_id` = `'84'`. We'll use the returned document to access a particular sentence and print out the `[i,j,k]` locations of the word `'monster'` from `index`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B4:SanityCheck\n",
    "\n",
    "# load the book\n",
    "document, index = load_book(\"84\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B4:SanityCHeck\n",
    "\n",
    "# Output paragraph 9, sentence 5\n",
    "document[9][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B4:SanityCheck\n",
    "\n",
    "# Output the indices for monster\n",
    "index['monster']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__B5.__ _(5 pts)_ Finally, make a new function called `fast_kwic` that takes a `document` and `index` from our new `load_book` function as well as a provided list of `search_terms` (just like our original kwic function). The function should loops through all specified `search_terms` to identify indices from `index[word]` for the key word-containing sentences and use them to extract these sentences from `document` into the same data structure as output by __B2__:\n",
    "```\n",
    "data['word'] = [[[i, j, k], [\"These\", \"are\", \"sentences\", \"containing\", \"the\", \"word\", \"'word'\", \".\"]],\n",
    "                ...,]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B5:Function(5/5)\n",
    "\n",
    "def fast_kwic(document, index, search_terms = {}):\n",
    "\n",
    "    #---Your code starts here---\n",
    "\n",
    "    #---Your code ends here---\n",
    "    \n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test our new function, lets test it on the same keywords as before: `Frankenstein` and `monster`. Note that the output from this sanity check should be the same as the one from **B3**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B5:SanityCheck\n",
    "\n",
    "fast_results = fast_kwic(document, index, {'Frankenstein', 'monster'})\n",
    "\n",
    "print(\"# of sentences 'Frankenstein' appears in: {}\".format(len(fast_results['Frankenstein'])))\n",
    "print(\"# of sentences 'monster' appears in: {}\".format(len(fast_results['monster'])))\n",
    "print()\n",
    "\n",
    "print(\" \".join(fast_results['Frankenstein'][7][1]))\n",
    "print()\n",
    "print(\" \".join(fast_results['monster'][0][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__B6.__ _(5 pts)_ Your goal here is to modify the pre-processing in `load_book` one more time! Make a small modification to the input: `load_book(book_id, pos = True, lemma = True):`, to accept two boolean arguments, `pos` and `lemma` specifying how to identify each word as a key term. In particular, each word will now be represented in both of the `document` and `index` as a tuple: `heading = (text, tag)`, where `text` contains the `word.text` attribute from `spacy` if `lemma = False`, and `word.lemma_` attribute if `True`. Similarly, `tag` should be left empty as `\"\"` if `pos = False` and otherwise contain `word.pos_`.\n",
    "\n",
    "Note this functions output should still consist of a `document` and `index` in the same format aside from the replacement of `word` with `heading`, which will allow for the same use of output in `fast_kwic`, although more specified by the textual features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B6:Function(5/5)\n",
    "\n",
    "def load_book(book_id, pos = True, lemma = True):\n",
    "    \n",
    "    #---Your code starts here---\n",
    "    \n",
    "    #---Your code ends here---\n",
    "    \n",
    "    return document, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B6:SanityCheck\n",
    "document, index = load_book(\"84\", pos = True, lemma = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B6:SanityCheck\n",
    "print(\"Sentence with ('cold', 'NOUN'):\")\n",
    "\" \".join(fast_kwic(document, index, search_terms = {('cold', 'NOUN')})[('cold', 'NOUN')][0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B6:SanityCheck\n",
    "print(\"Sentence with ('cold', 'ADJ'):\")\n",
    "\" \".join(fast_kwic(document, index, search_terms = {('cold', 'ADJ')})[('cold', 'ADJ')][0][1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
